# Production Hardening & Client-Ready Delivery Plan
## Updated: February 2, 2026

**Status:** PLAN-ONLY â€” Implementation awaits approval

---

## CLIENT REQUIREMENTS CONFIRMATION

Based on clarifying questions answered 2026-02-02:

### Scope Decisions

| Question | Answer | Impact on Plan |
|----------|--------|----------------|
| **Product Vision** | All three visions (CRM + Framework B + Plan Intelligence) | Keep all systems, ensure integration works |
| **V1 Features** | Template editor, RBAC UI, data import REQUIRED; investor dashboard DEFERRED | Must implement 3 major features |
| **Parent Repo** | Archive parent; clone needed files/schemas/databases carefully into CANONICAL | Add archival phase + selective cloning |
| **Deployment** | Vercel (env vars in parent, config files in CANONICAL) | Vercel deployment strategy |
| **Org Invite Flow** | Uncertain if client-requested | Verify during audit phase |
| **Timeline** | No fixed deadline, but respect Claude Code session limits | Design clean checkpoints for session handoff |
| **Data Migration** | Yes, Excel format via Google Drive | Implement Google Drive import feature |
| **Staging Environment** | Create before production | Add staging deployment phase |
| **Framework B** | Keep isolated but documented as optional | Feature flag approach |
| **Support SLA** | TBD later | Document as future decision point |

---

## 1. Executive Objective

Deliver a production-hardened, client-ready **integrated system** combining:
1. **Core CRM** (suppliers, projects, documents, tasks, deals, activities)
2. **Framework B** (AI RAG chatbot, document intelligence, vector search) â€” feature-flagged as optional
3. **Construction Plan Intelligence** (AI plan extraction, quote generation) â€” fully operational

"Production-hardened" means: all three systems work locally with passing tests (Playwright e2e), OpenAI API key fixed, database schema unified, parent repo archived, untracked code committed, git history clean, staging environment tested, and production deployable to Vercel with confidence.

"Client-ready" means: all contracted features implemented (supplier filter UI, template editor, RBAC UI, Google Drive data import), investor dashboard documented as Phase 2, client can understand the integrated system architecture, and all three visions work together without conflicts.

---

## 2. Canonicalization & Scope Alignment

### 2.1 Deliverable Product Vision

**Primary Deliverable:** ALL THREE VISIONS â€” Integrated System

**Components:**
1. **Vision 1 (Core CRM):** Suppliers, projects, documents, tasks, deals, activities, Supabase auth/RLS
2. **Vision 2 (Framework B â€” AI Intelligence):** RAG chatbot, document summarization, vector search (Pinecone), feature-flagged
3. **Vision 3 (Construction Plan Intelligence):** AI plan extraction (Python worker), quote generation, pricing engine

### 2.2 Integration Strategy

**Challenge:** Vision 2 (Quote Builder Master Plan) and Vision 3 (Construction Plan Intelligence) have overlapping scope but different implementations.

**Resolution:**
- Vision 3 is 80% implemented with `quotes` table schema
- Vision 2 is 0% implemented, planning artifact only
- **Decision:** Use Vision 3 as canonical quote system, archive Vision 2 master plan as reference documentation
- If Vision 2 features are needed later (lead capture, compliance checking), implement as extensions to Vision 3

**Database Schema Consolidation:**
- Keep: `quotes`, `quote_lines`, `price_books`, `price_items` (Vision 3)
- Archive: `quotations` table reference (Vision 2 â€” not implemented)
- Document schema in `DATABASE_SCHEMA.md`

### 2.3 Required Features (V1 Delivery)

| Feature | Status | Phase |
|---------|--------|-------|
| **Core CRM** | 95% complete | Phase 1-2 (clean up, test) |
| **Supplier filter UI** | Partially implemented (untracked files) | Phase 4 |
| **Template editor** | NOT IMPLEMENTED â€” REQUIRED | Phase 6 |
| **RBAC admin UI** | RLS exists, no UI â€” REQUIRED | Phase 7 |
| **Google Drive data import** | NOT IMPLEMENTED â€” REQUIRED | Phase 8 |
| **Framework B** | 100% implemented | Phase 5 (ensure operational, feature-flag) |
| **Plan Intelligence** | 80% implemented, broken (OpenAI key) | Phase 5 (fix, test) |
| **Investor dashboard** | NOT IMPLEMENTED â€” DEFERRED to Phase 2 | Document in ROADMAP.md |

### 2.4 Parent Repository Archival

**Parent Location:** `/Users/anitavallabha/goldarch_web_copy/`

**Status:** Contains duplicate/half-created/untested code, Vercel env vars

**Action Plan:**
1. **Phase 0A:** Archive entire parent directory to `/Users/anitavallabha/goldarch_web_copy/_recovery/ARCHIVE/parent_backup_2026-02-02/`
2. **Phase 0B:** Audit parent for needed resources:
   - Vercel env vars (`.env`, `.env.production`, `.env.local`)
   - Database schemas not in CANONICAL
   - Working code not in CANONICAL
   - Vercel configuration files
3. **Phase 0C:** Clone identified resources into CANONICAL at correct locations
4. **Phase 0D:** Add `DEPRECATED.md` to parent root warning against use
5. **Phase 0E:** Update all documentation to reference CANONICAL as sole working directory

---

## 3. Branch + PR + Review Workflow (Mandatory)

### 3.1 Repeatable Workflow Template

For **every** logical change:

#### Step 1: Verify Repository & Branch
```bash
# HARD REQUIREMENT: Must be in CANONICAL
pwd
# Expected: /Users/anitavallabha/goldarch_web_copy/_recovery/CANONICAL

# Verify git repo
git rev-parse --is-inside-work-tree

# Verify current branch
git branch --show-current

# Check working tree
git status
```

**Stop Condition:** If not in CANONICAL, STOP. If on wrong branch, STOP. If untracked files exist without plan, STOP.

#### Step 2: Create Feature Branch
```bash
# Branch naming: <type>/<short-description>
# Types: feat, fix, refactor, chore, docs, test
git checkout -b <type>/<description>
```

#### Step 3: Implement One Logical Unit
- Work on a single feature/fix/refactor
- Document changes inline with comments
- Track modified files

#### Step 4: Mandatory Self-Review (Code-Integration-Verifier)
Execute **ALL** applicable phases from `code-integration-verifier-SKILL.md`:
- Phase 1: Discovery & Analysis âœ“
- Phase 2: Plan Reconciliation âœ“
- Phase 3: Branch Strategy âœ“
- Phase 4: Code Implementation Review âœ“
- Phase 5: Integration Testing âœ“
- Phase 6: Commit Preparation âœ“
- Phase 7: Final Verification & Commit âœ“

**Stop Condition:** If ANY review fails, STOP. Fix the issue. Re-run the review. Do NOT proceed until all checks pass.

#### Step 5: Local Test Suite (Pre-Push Gate)
```bash
# Lint
npm run lint

# Build
npm run build

# Unit/integration tests
npm test

# Playwright e2e (critical flows)
npm run test:e2e
```

**Stop Condition:** Any failure = STOP. Do NOT push until all tests pass locally.

#### Step 6: Push & Create PR
```bash
git push -u origin <branch-name>
gh pr create --title "<type>: <short summary>" --body "$(cat <<'EOF'
## Summary
- **What:** [describe change]
- **Why:** [reason for change]
- **Source:** [which requirement/plan this addresses]
- **Branch:** [current branch]
- **Vision:** [CRM / Framework B / Plan Intelligence / Integration]

## Testing
- [ ] Local build passed
- [ ] Local tests passed
- [ ] Playwright e2e passed
- [ ] Manual testing: [describe]

## Checklist
- [ ] Code matches consolidated plan
- [ ] No scope creep mixed in
- [ ] All code-integration-verifier reviews completed
- [ ] No secrets/credentials committed
- [ ] Documentation updated (if applicable)
- [ ] Database migrations tested (if applicable)

## CodeRabbit Review Required
This PR requires CodeRabbit review before merge.
EOF
)"
```

**PR Naming Convention:**
```
<type>: <concise description>

Examples:
feat: add supplier region filter UI
fix: resolve OpenAI API key configuration for plan intelligence
refactor: consolidate quote systems (Vision 2 + 3)
chore: commit untracked supplier filter files
feat: implement template editor for quotations
```

#### Step 7: CodeRabbit Review Loop
1. Wait for CodeRabbit automated review
2. Address ALL comments and suggestions
3. Push fixes to the same branch
4. Re-request review if needed
5. Obtain approval

**Stop Condition:** Do NOT merge without CodeRabbit approval.

#### Step 8: Merge Criteria
Only merge when:
- [ ] CodeRabbit approved
- [ ] All CI checks pass (if configured)
- [ ] No merge conflicts
- [ ] Squash/merge commit message is clear

```bash
gh pr merge --squash --delete-branch
```

### 3.2 Branch Strategy

**Main Branch:** `main` (production-ready code only)

**Feature Branches:** `feat/<description>`, `fix/<description>`, `refactor/<description>`, `chore/<description>`

**No Direct Commits to Main:** All changes go through PR workflow.

**Session Handoff Strategy:**
- At end of each session, ensure:
  - Current work committed to feature branch
  - Branch pushed to remote
  - Status documented in `SESSION_HANDOFF.md` with next steps
  - No uncommitted changes in working tree

---

## 4. Step-by-Step Delivery Plan (Phased)

### PHASE 0A: Parent Repository Archival

**Purpose:** Archive parent repo, preserve resources, establish CANONICAL as sole working directory.

**Entry Criteria:**
- None (starting point)

**Actions:**
1. Verify CANONICAL exists and is functional:
   ```bash
   cd /Users/anitavallabha/goldarch_web_copy/_recovery/CANONICAL
   pwd
   ```
2. Create archive directory:
   ```bash
   mkdir -p /Users/anitavallabha/goldarch_web_copy/_recovery/ARCHIVE/parent_backup_2026-02-02
   ```
3. Copy parent contents to archive (NOT move, preserve parent for now):
   ```bash
   cp -R /Users/anitavallabha/goldarch_web_copy/* /Users/anitavallabha/goldarch_web_copy/_recovery/ARCHIVE/parent_backup_2026-02-02/ 2>/dev/null || true
   # Ignore errors for nested directories
   ```
4. Create inventory of parent resources:
   ```bash
   cd /Users/anitavallabha/goldarch_web_copy/
   find . -name ".env*" -type f > /tmp/parent_env_files.txt
   find . -name "vercel.json" -type f >> /tmp/parent_resources.txt
   find . -name "supabase/migrations/*" -type f >> /tmp/parent_resources.txt
   cat /tmp/parent_resources.txt
   ```
5. Document findings in `PARENT_ARCHIVE_INVENTORY.md`

**Verification:**
```bash
ls -la /Users/anitavallabha/goldarch_web_copy/_recovery/ARCHIVE/parent_backup_2026-02-02/
# Confirm backup exists
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- Phase 1: Discovery & Analysis
  - [ ] Identified all resources in parent
  - [ ] Backup verified
  - [ ] Inventory documented

**PR Gate:** None (filesystem operation only)

**Exit Criteria:**
- [ ] Parent fully backed up
- [ ] Inventory of parent resources documented
- [ ] CANONICAL verified as functional

**Stop Condition:** If backup fails, STOP, investigate disk space/permissions.

---

### PHASE 0B: Resource Cloning from Parent

**Purpose:** Clone needed resources (Vercel env vars, schemas, configs) from parent into CANONICAL.

**Entry Criteria:**
- [ ] Phase 0A complete
- [ ] Inventory of parent resources available

**Actions:**
1. Create feature branch in CANONICAL:
   ```bash
   cd /Users/anitavallabha/goldarch_web_copy/_recovery/CANONICAL
   git checkout -b chore/clone-parent-resources
   ```
2. Review parent inventory `PARENT_ARCHIVE_INVENTORY.md`
3. For each needed resource, clone into CANONICAL:

   **Vercel env vars:**
   ```bash
   # Review parent .env files
   cat /Users/anitavallabha/goldarch_web_copy/.env
   cat /Users/anitavallabha/goldarch_web_copy/.env.production
   cat /Users/anitavallabha/goldarch_web_copy/.env.local

   # Copy valid env vars to CANONICAL/.env (merge, don't overwrite)
   # MANUAL REVIEW: Don't blindly copy, merge keys
   ```

   **Vercel config:**
   ```bash
   # Check if vercel.json exists in parent
   cat /Users/anitavallabha/goldarch_web_copy/vercel.json

   # Copy to CANONICAL if not present
   cp /Users/anitavallabha/goldarch_web_copy/vercel.json /Users/anitavallabha/goldarch_web_copy/_recovery/CANONICAL/vercel.json
   ```

   **Database schemas (if missing in CANONICAL):**
   ```bash
   # Compare parent and CANONICAL migrations
   diff -r /Users/anitavallabha/goldarch_web_copy/supabase/migrations/ /Users/anitavallabha/goldarch_web_copy/_recovery/CANONICAL/supabase/migrations/

   # Copy missing migrations carefully (check for conflicts)
   ```

4. Verify no duplicates or conflicts
5. Document cloned resources in `CLONED_FROM_PARENT.md`

**Verification:**
```bash
# Verify env vars valid
cat .env | grep -i "api_key\|url"

# Verify vercel.json valid JSON
cat vercel.json | jq .

# Verify migrations don't conflict
ls -la supabase/migrations/
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- Phase 2: Plan Reconciliation
  - [ ] No conflicting env vars
  - [ ] Vercel config valid
  - [ ] Migrations don't duplicate
- Phase 4: Code Implementation Review
  - [ ] Only needed resources cloned
  - [ ] No unnecessary files

**PR Gate:**
1. Push branch
2. Create PR: "chore: clone needed resources from parent repo"
3. CodeRabbit review
4. Merge to `main`

**Exit Criteria:**
- [ ] All needed resources cloned to CANONICAL
- [ ] No conflicts
- [ ] Documentation updated
- [ ] PR merged

**Stop Condition:** If conflicts found, STOP, manually resolve before committing.

---

### PHASE 0C: Parent Deprecation

**Purpose:** Mark parent repo as deprecated, prevent accidental use.

**Entry Criteria:**
- [ ] Phase 0B complete
- [ ] All needed resources in CANONICAL

**Actions:**
1. Create `DEPRECATED.md` in parent root:
   ```bash
   cd /Users/anitavallabha/goldarch_web_copy/
   cat > DEPRECATED.md <<'EOF'
   # âš ï¸ DEPRECATED REPOSITORY

   **This repository is DEPRECATED as of 2026-02-02.**

   ## DO NOT USE THIS DIRECTORY FOR DEVELOPMENT

   **Canonical working directory:** `/Users/anitavallabha/goldarch_web_copy/_recovery/CANONICAL`

   This directory contains duplicate, half-created, or untested code. All active development occurs in CANONICAL.

   ## Backup

   Full backup archived at: `/Users/anitavallabha/goldarch_web_copy/_recovery/ARCHIVE/parent_backup_2026-02-02/`

   ## Resources Cloned to CANONICAL

   See CANONICAL/CLONED_FROM_PARENT.md for inventory.

   ## If You Need Something From Here

   1. Check if it exists in CANONICAL first
   2. If not, carefully clone to CANONICAL (don't modify parent)
   3. Document in CANONICAL/CLONED_FROM_PARENT.md
   EOF
   ```
2. Optionally rename parent to signal deprecation:
   ```bash
   # OPTIONAL: Rename parent directory
   cd /Users/anitavallabha/goldarch_web_copy/../
   mv goldarch_web_copy goldarch_web_copy_DEPRECATED_2026-02-02
   # Update paths in this plan if renamed
   ```

**Verification:**
```bash
cat /Users/anitavallabha/goldarch_web_copy/DEPRECATED.md
# Confirm file exists and content correct
```

**Mandatory Self-Review:**
- [ ] Parent clearly marked as deprecated
- [ ] CANONICAL documented as canonical

**PR Gate:** None (parent directory, not git-controlled work)

**Exit Criteria:**
- [ ] Parent marked deprecated
- [ ] No risk of accidental use

**Stop Condition:** None

---

### PHASE 1: Repository Audit & Baseline Verification

**Purpose:** Confirm CANONICAL is correct working repository, establish clean baseline, verify current functionality.

**Entry Criteria:**
- [ ] Phase 0A-0C complete
- [ ] CANONICAL is sole working directory

**Actions:**
1. Verify working directory:
   ```bash
   cd /Users/anitavallabha/goldarch_web_copy/_recovery/CANONICAL
   pwd
   ```
2. Confirm git repository:
   ```bash
   git rev-parse --is-inside-work-tree
   git branch --show-current
   git status
   ```
3. Document ALL untracked/modified files
4. Verify `.env` configuration:
   ```bash
   cat .env | grep -i "openai\|supabase\|pinecone\|vercel"
   # Check for invalid/expired keys
   ```
5. Install dependencies:
   ```bash
   npm install
   ```
6. Build:
   ```bash
   npm run build
   ```
7. Run existing tests:
   ```bash
   npm test
   ```
8. Manual test all CRM routes:
   - /app-dashboard/activities
   - /app-dashboard/deals
   - /app-dashboard/documents
   - /app-dashboard/projects
   - /app-dashboard/quotes
   - /app-dashboard/suppliers
   - /app-dashboard/tasks
9. Test Framework B routes:
   - /api/framework-b/health
   - /app-dashboard/documents (AI chat widget)
10. Test Plan Intelligence routes:
    - /app-dashboard/plans
    - /api/plans/upload
11. Document working vs. broken features
12. Review Supabase migrations:
    ```bash
    ls -la supabase/migrations/
    ```

**Verification:**
```bash
npm run build
# Build succeeds

npm test
# Tests run (pass or fail documented)

# Manual testing checklist
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- Phase 1: Discovery & Analysis
  - [ ] All plan files identified (PROJECT_STATE_ANALYSIS_REPORT.md, this plan, etc.)
  - [ ] Current git branch structure understood
  - [ ] All uncommitted changes documented
  - [ ] Potential conflicts identified

**PR Gate:** None (read-only audit)

**Exit Criteria:**
- [ ] CANONICAL confirmed as active repo
- [ ] Current branch documented (likely `main` or `feat/invite-e2e`)
- [ ] Untracked files documented
- [ ] Build succeeds
- [ ] Core routes render
- [ ] Known issues documented:
  - OpenAI API key invalid (blocks Plan Intelligence)
  - Python worker idle
  - Any broken routes
- [ ] Audit report written: `BASELINE_AUDIT_2026-02-02.md`

**Stop Condition:** If build fails completely, STOP, investigate critical errors.

---

### PHASE 2: Clean Working Tree & Commit Untracked Work

**Purpose:** Commit or remove all untracked files to establish clean git baseline. Prioritize supplier filter work (client requirement).

**Entry Criteria:**
- [ ] Phase 1 complete
- [ ] Baseline audit documented

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b chore/commit-untracked-work
   ```
2. Review each untracked file from git status:
   - `app/api/suppliers/` â€” inspect contents, determine if functional
   - `lib/middleware/supplier-filter.ts` â€” inspect, likely part of client-required access control
   - `lib/utils/search-query-builder.ts` â€” inspect for relevance
   - `lib/utils/supplier-query-builder.ts` â€” inspect for relevance
   - `supabase/migrations/20260129000000_create_supplier_access_rules.sql` â€” inspect migration
   - `scripts/test_e2e_invite.mjs` â€” test artifact for org invite flow
   - `scripts/verify_alignment.report.json` â€” test output, likely temporary
   - `test_invite.mjs` â€” test artifact
   - `test-results/` â€” Playwright test results, add to `.gitignore`
3. Decision matrix:

   | File | Action | Reason |
   |------|--------|--------|
   | `app/api/suppliers/*` | Inspect â†’ Commit if functional | Likely API routes for supplier filter |
   | `lib/middleware/supplier-filter.ts` | Commit | Part of client-required feature |
   | `lib/utils/search-query-builder.ts` | Commit | Utility for supplier filter |
   | `lib/utils/supplier-query-builder.ts` | Commit | Utility for supplier filter |
   | `supabase/migrations/20260129000000_create_supplier_access_rules.sql` | Review â†’ Commit if safe | Database migration for access control |
   | `scripts/test_e2e_invite.mjs` | Commit | Test for org invite flow |
   | `scripts/verify_alignment.report.json` | Add to `.gitignore` | Temporary test output |
   | `test_invite.mjs` | Commit | Test artifact |
   | `test-results/` | Add to `.gitignore` | Playwright output directory |
   | `next-env.d.ts` (modified) | Review changes â†’ Commit | TypeScript definitions |

4. Stage files:
   ```bash
   git add app/api/suppliers/
   git add lib/middleware/supplier-filter.ts
   git add lib/utils/search-query-builder.ts
   git add lib/utils/supplier-query-builder.ts
   git add supabase/migrations/20260129000000_create_supplier_access_rules.sql
   git add scripts/test_e2e_invite.mjs
   git add test_invite.mjs
   git add next-env.d.ts

   # Add to .gitignore
   echo "test-results/" >> .gitignore
   echo "scripts/verify_alignment.report.json" >> .gitignore
   git add .gitignore
   ```

5. Build and test:
   ```bash
   npm run build
   npm test
   ```

6. Commit:
   ```bash
   git commit -m "chore: commit untracked supplier filter work and test files

   - Add supplier API routes (app/api/suppliers/)
   - Add supplier filter middleware and utilities
   - Add supplier access rules migration
   - Add org invite e2e tests
   - Update .gitignore for test artifacts

   These files implement client-required supplier access control feature.

   ðŸ¤– Generated with Claude Code

   Co-Authored-By: Claude <noreply@anthropic.com>"
   ```

**Verification:**
```bash
git status
# Clean working tree

npm run build
# Build succeeds

git diff --cached
# Review staged changes
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- Phase 2: Plan Reconciliation
  - [ ] Determined which files are canonical vs. temporary
  - [ ] No conflicts with existing code
- Phase 3: Branch Strategy
  - [ ] On correct branch `chore/commit-untracked-work`
- Phase 4: Code Implementation Review
  - [ ] Changes match plan (commit untracked supplier work)
- Phase 5: Integration Testing
  - [ ] Build succeeds
  - [ ] No broken imports
- Phase 6: Commit Preparation
  - [ ] Commit message accurate
  - [ ] Only related files staged
- Phase 7: Final Verification & Commit
  - [ ] Commit created successfully

**PR Gate:**
1. Push: `git push -u origin chore/commit-untracked-work`
2. Create PR
3. CodeRabbit review
4. Merge to `main`

**Exit Criteria:**
- [ ] Clean working tree
- [ ] Supplier filter work committed
- [ ] Build passes
- [ ] PR merged

**Stop Condition:** If committing breaks build, STOP, isolate problematic files.

---

### PHASE 3: Fix OpenAI API Key & Enable Plan Intelligence

**Purpose:** Fix invalid OpenAI API key blocking Plan Intelligence, verify Python worker functional.

**Entry Criteria:**
- [ ] Phase 2 complete
- [ ] Clean working tree

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b fix/openai-api-key-plan-intelligence
   ```
2. Obtain valid OpenAI API key:
   - Generate new key from OpenAI dashboard
   - Store in `.env` (NOT committed to git)
3. Update `.env`:
   ```bash
   # Open .env in editor
   # Replace:
   OPENAI_API_KEY=sk-...truncated/invalid
   # With:
   OPENAI_API_KEY=sk-proj-...VALID_KEY
   ```
4. Update `.env.example` with placeholder:
   ```bash
   # Add to .env.example
   OPENAI_API_KEY=sk-proj-your-key-here
   ```
5. Verify Python worker configuration:
   ```bash
   # Find worker process
   ps aux | grep python | grep worker

   # If running, kill and restart with new env
   pkill -f "python.*worker"

   # Start worker (assumes worker script exists)
   # Check for worker start script in package.json or scripts/
   npm run worker:start
   # OR
   python3 scripts/plan_extraction_worker.py &
   ```
6. Test Plan Intelligence:
   - Upload test construction plan PDF
   - Verify worker processes job
   - Verify quote generated
7. Document worker management in `WORKER_MANAGEMENT.md`

**Verification:**
```bash
# Test API endpoint
curl http://localhost:3000/api/plans/health
# Should return success

# Check worker logs
tail -f logs/worker.log
# (if logs exist)

# Manual test: upload plan, check processing
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- All phases (1-7)
- Specific focus:
  - [ ] OpenAI API key valid
  - [ ] No secrets committed to git
  - [ ] Worker processes jobs
  - [ ] Plan Intelligence functional

**PR Gate:**
1. Push branch (`.env` NOT pushed, only `.env.example`)
2. Create PR: "fix: update OpenAI API key configuration and worker management"
3. CodeRabbit review
4. Merge to `main`

**Exit Criteria:**
- [ ] Valid OpenAI API key configured
- [ ] Python worker functional
- [ ] Plan Intelligence processes test job successfully
- [ ] Documentation updated
- [ ] PR merged

**Stop Condition:** If worker fails to process jobs after key update, STOP, debug worker code.

---

### PHASE 4: Complete Supplier Filter UI (Client Requirement)

**Purpose:** Finish implementing supplier filter UI with region/category filtering at user access level.

**Entry Criteria:**
- [ ] Phase 3 complete
- [ ] Supplier filter files committed (Phase 2)

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b feat/supplier-filter-ui-complete
   ```
2. Review committed supplier filter code:
   - `app/api/suppliers/*` â€” API routes
   - `lib/middleware/supplier-filter.ts` â€” middleware
   - `lib/utils/supplier-query-builder.ts` â€” query builder
   - `supabase/migrations/20260129000000_create_supplier_access_rules.sql` â€” migration
3. Apply migration if not already applied:
   ```bash
   npx supabase db push
   ```
4. Implement missing pieces:

   **Admin UI for access rules:**
   - Create `/app-dashboard/admin/supplier-access` page
   - UI to assign users to supplier categories/regions
   - Example: "User Joy can only see Kitchen suppliers in Mumbai region"

   **User-facing filtered list:**
   - Update `/app-dashboard/suppliers` to respect access rules
   - Integrate with existing RLS policies
   - User sees only suppliers they have access to

   **API routes:**
   - `POST /api/suppliers/access-rules` â€” create access rule
   - `GET /api/suppliers/access-rules` â€” list rules
   - `DELETE /api/suppliers/access-rules/:id` â€” delete rule

5. Write Playwright test (`tests/e2e/supplier-filter.spec.ts`):
   ```typescript
   // Example test structure
   test('admin assigns supplier access rule', async ({ page }) => {
     // Login as admin
     // Navigate to /app-dashboard/admin/supplier-access
     // Create rule: User Joy â†’ Kitchen category â†’ Mumbai region
     // Verify rule created
   });

   test('restricted user sees filtered suppliers', async ({ page }) => {
     // Login as Joy
     // Navigate to /app-dashboard/suppliers
     // Verify only Kitchen suppliers shown
     // Verify other categories not visible
   });
   ```
6. Run test locally:
   ```bash
   npm run test:e2e
   ```

**Verification:**
```bash
npm run build
npm test
npm run test:e2e

# Manual test:
# 1. Login as admin
# 2. Create access rule: test user â†’ Kitchen â†’ Mumbai
# 3. Logout
# 4. Login as test user
# 5. View /app-dashboard/suppliers
# 6. Verify only Kitchen suppliers in Mumbai shown
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- All phases (1-7)
- Specific focus:
  - [ ] Implements client requirement (access control)
  - [ ] RLS policies secure (no SQL injection)
  - [ ] Playwright test passes
  - [ ] UI intuitive
  - [ ] No security vulnerabilities

**PR Gate:**
1. Push branch
2. Create PR: "feat: implement supplier filter UI with role-based access control"
3. CodeRabbit review (expect security feedback on RLS)
4. Merge to `main`

**Exit Criteria:**
- [ ] Admin can create/delete supplier access rules
- [ ] Users see filtered supplier lists based on rules
- [ ] RLS policies enforced
- [ ] Playwright test passes
- [ ] PR merged

**Stop Condition:** If Playwright test fails or security issues found, STOP, fix before merging.

---

### PHASE 5: Ensure Framework B Operational + Feature Flag

**Purpose:** Verify Framework B (AI RAG) works, implement feature flag for optional enablement.

**Entry Criteria:**
- [ ] Phase 4 complete
- [ ] OpenAI API key valid (from Phase 3)

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b feat/framework-b-feature-flag
   ```
2. Audit Framework B components:
   - `/app/api/framework-b/*` â€” health, upload, search, summarize, chat
   - `Framework_B_Implementation/` â€” service layer
   - `components/ai-chat-widget.tsx` â€” UI component
   - Pinecone integration
   - OpenAI embeddings
3. Test Framework B endpoints:
   ```bash
   curl http://localhost:3000/api/framework-b/health
   # Verify returns success

   # Test document upload + chat
   # Manual test via UI: upload document, ask question in chat
   ```
4. Implement feature flag:

   **Add env var:**
   ```bash
   # .env
   NEXT_PUBLIC_ENABLE_FRAMEWORK_B=true

   # .env.example
   NEXT_PUBLIC_ENABLE_FRAMEWORK_B=false
   ```

   **Conditional rendering:**
   ```typescript
   // components/ai-chat-widget.tsx
   export function AIChatWidget() {
     if (process.env.NEXT_PUBLIC_ENABLE_FRAMEWORK_B !== 'true') {
       return null;
     }
     // existing component
   }
   ```

   **Route guards:**
   ```typescript
   // app/api/framework-b/*/route.ts
   if (process.env.NEXT_PUBLIC_ENABLE_FRAMEWORK_B !== 'true') {
     return NextResponse.json({ error: 'Feature disabled' }, { status: 404 });
   }
   ```

5. Test with feature flag OFF:
   ```bash
   # Set NEXT_PUBLIC_ENABLE_FRAMEWORK_B=false
   npm run build
   # Verify chat widget not rendered
   # Verify API returns 404
   ```
6. Test with feature flag ON:
   ```bash
   # Set NEXT_PUBLIC_ENABLE_FRAMEWORK_B=true
   npm run build
   # Verify chat widget renders
   # Verify API functional
   ```
7. Document in `OPTIONAL_FEATURES.md`:
   ```markdown
   # Framework B (AI Document Intelligence)

   **Status:** Optional feature, disabled by default

   **Enable:** Set `NEXT_PUBLIC_ENABLE_FRAMEWORK_B=true` in `.env`

   **Features:**
   - AI-powered document chat
   - Vector search (Pinecone)
   - Document summarization

   **Requirements:**
   - Valid OpenAI API key
   - Valid Pinecone API key
   ```

**Verification:**
```bash
npm run build
# Test with flag ON and OFF

curl http://localhost:3000/api/framework-b/health
# Verify feature flag respected
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- All phases (1-7)
- Specific focus:
  - [ ] Framework B works when enabled
  - [ ] Core CRM works when Framework B disabled
  - [ ] Feature flag properly implemented
  - [ ] Documentation clear

**PR Gate:**
1. Push branch
2. Create PR: "feat: add feature flag for Framework B (AI document intelligence)"
3. CodeRabbit review
4. Merge to `main`

**Exit Criteria:**
- [ ] Framework B functional when enabled
- [ ] Feature flag works
- [ ] Documentation updated
- [ ] PR merged

**Stop Condition:** If Framework B broken, STOP, debug before proceeding.

---

### PHASE 6: Implement Template Editor (Client Requirement)

**Purpose:** Build template editor for quotations, invoices, emails (client-required feature).

**Entry Criteria:**
- [ ] Phase 5 complete

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b feat/template-editor
   ```
2. Design template system:

   **Database schema:**
   ```sql
   -- supabase/migrations/20260203000000_create_templates.sql
   CREATE TABLE templates (
     id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
     name TEXT NOT NULL,
     type TEXT NOT NULL CHECK (type IN ('quotation', 'invoice', 'email')),
     content JSONB NOT NULL, -- template structure
     variables JSONB, -- available variables like {{customer_name}}
     organization_id UUID REFERENCES organizations(id),
     created_at TIMESTAMPTZ DEFAULT NOW(),
     updated_at TIMESTAMPTZ DEFAULT NOW()
   );

   CREATE INDEX idx_templates_org ON templates(organization_id);
   CREATE INDEX idx_templates_type ON templates(type);
   ```

   **Template structure (JSONB):**
   ```json
   {
     "quotation": {
       "header": "{{company_name}} - Quotation",
       "body": "Dear {{customer_name}},\n\nPlease find the quotation for {{project_name}}...",
       "footer": "Terms and conditions..."
     }
   }
   ```
3. Implement UI:
   - Create `/app-dashboard/admin/templates` page
   - Template list (quotations, invoices, emails)
   - Template editor (rich text or markdown)
   - Variable picker ({{customer_name}}, {{project_name}}, etc.)
   - Preview with sample data
4. Implement API routes:
   - `GET /api/templates` â€” list templates
   - `POST /api/templates` â€” create template
   - `PUT /api/templates/:id` â€” update template
   - `DELETE /api/templates/:id` â€” delete template
   - `POST /api/templates/:id/render` â€” render template with data
5. Integrate with existing features:
   - When generating quotation, select template
   - Render template with actual project/customer data
6. Write Playwright test:
   ```typescript
   test('admin creates quotation template', async ({ page }) => {
     // Login as admin
     // Navigate to /app-dashboard/admin/templates
     // Create new quotation template
     // Add variables {{customer_name}}, {{total}}
     // Preview with sample data
     // Save template
   });

   test('user generates quotation from template', async ({ page }) => {
     // Login as user
     // Navigate to project
     // Generate quotation
     // Select template
     // Verify rendered quotation
   });
   ```

**Verification:**
```bash
npm run build
npm test
npm run test:e2e

# Manual test:
# 1. Create quotation template
# 2. Generate quotation from project
# 3. Verify template rendered correctly
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- All phases (1-7)
- Specific focus:
  - [ ] Implements client requirement
  - [ ] Template editor functional
  - [ ] Variable substitution works
  - [ ] RLS policies for templates

**PR Gate:**
1. Push branch
2. Create PR: "feat: implement template editor for quotations, invoices, emails"
3. CodeRabbit review
4. Merge to `main`

**Exit Criteria:**
- [ ] Template CRUD functional
- [ ] Template editor UI works
- [ ] Templates render with data
- [ ] Playwright test passes
- [ ] PR merged

**Stop Condition:** If template rendering fails, STOP, debug before merging.

---

### PHASE 7: Implement RBAC Admin UI (Client Requirement)

**Purpose:** Build admin UI for role-based access control (currently RLS exists but no UI).

**Entry Criteria:**
- [ ] Phase 6 complete

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b feat/rbac-admin-ui
   ```
2. Audit existing RLS policies:
   ```bash
   # Review Supabase RLS policies
   npx supabase db dump --schema public > /tmp/current_schema.sql
   grep "POLICY" /tmp/current_schema.sql
   ```
3. Design RBAC system:

   **Roles:**
   - Admin (full access)
   - Manager (project management)
   - Staff (limited access)
   - Viewer (read-only)

   **Database schema:**
   ```sql
   -- supabase/migrations/20260204000000_create_rbac.sql
   CREATE TABLE roles (
     id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
     name TEXT NOT NULL UNIQUE,
     permissions JSONB NOT NULL,
     organization_id UUID REFERENCES organizations(id),
     created_at TIMESTAMPTZ DEFAULT NOW()
   );

   CREATE TABLE user_roles (
     user_id UUID REFERENCES auth.users(id),
     role_id UUID REFERENCES roles(id),
     organization_id UUID REFERENCES organizations(id),
     created_at TIMESTAMPTZ DEFAULT NOW(),
     PRIMARY KEY (user_id, role_id, organization_id)
   );
   ```

   **Permissions structure (JSONB):**
   ```json
   {
     "suppliers": ["create", "read", "update", "delete"],
     "projects": ["read"],
     "templates": []
   }
   ```
4. Implement Admin UI:
   - Create `/app-dashboard/admin/roles` page
   - List roles
   - Create/edit role with permission checkboxes
   - Assign roles to users
5. Implement API routes:
   - `GET /api/rbac/roles` â€” list roles
   - `POST /api/rbac/roles` â€” create role
   - `PUT /api/rbac/roles/:id` â€” update role
   - `DELETE /api/rbac/roles/:id` â€” delete role
   - `POST /api/rbac/users/:userId/roles` â€” assign role to user
6. Update RLS policies to use role permissions:
   ```sql
   -- Example: suppliers table
   CREATE POLICY "Users can view suppliers based on role"
     ON suppliers FOR SELECT
     USING (
       EXISTS (
         SELECT 1 FROM user_roles ur
         JOIN roles r ON r.id = ur.role_id
         WHERE ur.user_id = auth.uid()
         AND r.permissions->'suppliers' ? 'read'
       )
     );
   ```
7. Write Playwright test:
   ```typescript
   test('admin creates role and assigns to user', async ({ page }) => {
     // Login as admin
     // Create role "Manager" with supplier read/update permissions
     // Assign role to test user
     // Logout, login as test user
     // Verify test user can view/update suppliers
     // Verify test user cannot delete suppliers
   });
   ```

**Verification:**
```bash
npm run build
npm test
npm run test:e2e

# Manual test:
# 1. Create role "Viewer" with read-only permissions
# 2. Assign to test user
# 3. Login as test user
# 4. Verify can view but not edit
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- All phases (1-7)
- Specific focus:
  - [ ] Implements client requirement
  - [ ] RLS policies secure
  - [ ] Role assignments work
  - [ ] No privilege escalation vulnerabilities

**PR Gate:**
1. Push branch
2. Create PR: "feat: implement RBAC admin UI with role management"
3. CodeRabbit review (expect security focus)
4. Merge to `main`

**Exit Criteria:**
- [ ] Admin can create/manage roles
- [ ] Admin can assign roles to users
- [ ] RLS policies enforce role permissions
- [ ] Playwright test passes
- [ ] PR merged

**Stop Condition:** If security vulnerabilities found, STOP, fix before merging.

---

### PHASE 8: Implement Google Drive Data Import (Client Requirement)

**Purpose:** Build Google Drive integration for Excel data migration.

**Entry Criteria:**
- [ ] Phase 7 complete

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b feat/google-drive-data-import
   ```
2. Set up Google Drive API:
   - Create Google Cloud project
   - Enable Google Drive API
   - Create OAuth 2.0 credentials
   - Add credentials to `.env`:
     ```bash
     GOOGLE_CLIENT_ID=...
     GOOGLE_CLIENT_SECRET=...
     GOOGLE_REDIRECT_URI=http://localhost:3000/api/auth/google/callback
     ```
3. Implement Google Drive OAuth:
   - Create `/api/auth/google/authorize` â€” redirect to Google OAuth
   - Create `/api/auth/google/callback` â€” handle OAuth callback, store token
4. Implement import UI:
   - Create `/app-dashboard/admin/import` page
   - Button: "Connect Google Drive"
   - File picker: list Excel files from connected Drive
   - Select file â†’ preview data
   - Map columns to database fields:
     - Excel column "Company Name" â†’ suppliers.name
     - Excel column "Category" â†’ suppliers.category
   - Validate data
   - Import button
5. Implement import processing:
   - Create `/api/import/google-drive` route
   - Download Excel file from Google Drive
   - Parse Excel (use library like `xlsx`)
   - Validate rows:
     - Required fields present
     - Data types correct
     - No duplicates
   - Insert into database (suppliers, projects, tasks, etc.)
   - Return import report (success count, errors)
6. Handle errors gracefully:
   - Invalid file format â†’ show error
   - Missing columns â†’ show mapping UI
   - Duplicate records â†’ offer update or skip
7. Write Playwright test:
   ```typescript
   test('admin imports suppliers from Google Drive', async ({ page }) => {
     // Mock Google Drive OAuth (use test account)
     // Login as admin
     // Navigate to /app-dashboard/admin/import
     // Connect Google Drive
     // Select test Excel file
     // Map columns
     // Import
     // Verify suppliers imported
   });
   ```
8. Document in `DATA_IMPORT_GUIDE.md`:
   - How to connect Google Drive
   - Excel file format requirements
   - Column mapping
   - Error handling

**Verification:**
```bash
npm run build
npm test
npm run test:e2e

# Manual test:
# 1. Connect Google Drive
# 2. Upload test Excel file to Drive
# 3. Import file
# 4. Verify data imported correctly
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- All phases (1-7)
- Specific focus:
  - [ ] Implements client requirement
  - [ ] OAuth flow secure
  - [ ] Data validation robust
  - [ ] No data corruption

**PR Gate:**
1. Push branch
2. Create PR: "feat: implement Google Drive Excel data import"
3. CodeRabbit review
4. Merge to `main`

**Exit Criteria:**
- [ ] Google Drive OAuth works
- [ ] Excel files can be imported
- [ ] Data validation functional
- [ ] Import errors handled gracefully
- [ ] Playwright test passes
- [ ] PR merged

**Stop Condition:** If OAuth fails or data import corrupts database, STOP, debug before merging.

---

### PHASE 9: Configuration Hardening & Security Audit

**Purpose:** Secure configuration, audit for secrets, prepare for production.

**Entry Criteria:**
- [ ] Phases 1-8 complete
- [ ] All feature PRs merged to `main`

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b chore/config-hardening
   ```
2. Audit `.env`:
   ```bash
   cat .env | grep -i "api_key\|secret\|password"
   # Verify all keys valid, not expired
   ```
3. Check for secrets in git history:
   ```bash
   git log -p | grep -E "sk-|pk_|eyJ" | head -20
   # If secrets found, use git-filter-repo to remove
   ```
4. Update `.env.example` with all required variables:
   ```bash
   # .env.example
   NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
   SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
   OPENAI_API_KEY=sk-proj-your-key
   PINECONE_API_KEY=your-pinecone-key
   GOOGLE_CLIENT_ID=your-google-client-id
   GOOGLE_CLIENT_SECRET=your-google-client-secret
   NEXT_PUBLIC_ENABLE_FRAMEWORK_B=false
   ```
5. Security checklist:
   - [ ] Supabase RLS enabled on ALL tables
   - [ ] API routes require authentication
   - [ ] No SQL injection vulnerabilities (use parameterized queries)
   - [ ] No XSS vulnerabilities (sanitize user input)
   - [ ] CORS configured (only allow production domain)
   - [ ] Rate limiting enabled (Upstash Redis)
   - [ ] Input validation on all forms
   - [ ] File upload validation (file type, size limits)
6. Run security audit:
   ```bash
   npm audit
   npm audit fix
   # Review and fix critical/high vulnerabilities
   ```
7. Test authentication/authorization:
   - Try accessing protected routes without login â†’ should redirect
   - Try accessing admin routes as normal user â†’ should deny
   - Try viewing supplier outside access rules â†’ should deny
8. Document security posture in `SECURITY.md`:
   - Authentication methods
   - RLS policies
   - API security
   - Known limitations
   - Reporting vulnerabilities

**Verification:**
```bash
npm audit
# No critical vulnerabilities

# Manual security testing:
# 1. Access protected API route without auth â†’ 401
# 2. Attempt SQL injection in search â†’ sanitized
# 3. Attempt XSS in form â†’ sanitized
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- All phases (1-7)
- Specific focus:
  - [ ] No secrets in git history
  - [ ] All API keys valid
  - [ ] Security vulnerabilities addressed
  - [ ] RLS policies tested

**PR Gate:**
1. Push branch
2. Create PR: "chore: security hardening and configuration audit"
3. CodeRabbit review (expect security-focused feedback)
4. Merge to `main`

**Exit Criteria:**
- [ ] No secrets in git
- [ ] All env vars documented
- [ ] No critical security vulnerabilities
- [ ] Security testing passed
- [ ] PR merged

**Stop Condition:** If secrets found in git history, STOP, cleanse before proceeding.

---

### PHASE 10: Comprehensive Playwright E2E Test Suite

**Purpose:** Expand e2e test coverage for all critical flows.

**Entry Criteria:**
- [ ] Phase 9 complete
- [ ] All features implemented

**Actions:**
1. Create feature branch:
   ```bash
   git checkout main
   git pull origin main
   git checkout -b test/comprehensive-e2e
   ```
2. Audit existing tests:
   ```bash
   ls -la tests/e2e/
   # Identify existing tests
   ```
3. Define critical flows (beyond individual feature tests):

   **Core CRM Flows:**
   - User registration â†’ login â†’ create supplier â†’ create project â†’ add task â†’ complete task â†’ logout
   - Admin creates user â†’ assigns role â†’ user logs in â†’ verifies limited access

   **Supplier Management Flow:**
   - Admin creates supplier categories â†’ assigns access rules â†’ restricted user views filtered list

   **Document Management Flow:**
   - User uploads document â†’ AI chat (if Framework B enabled) â†’ download â†’ delete

   **Template Flow:**
   - Admin creates quotation template â†’ user generates quote from template â†’ verify rendered

   **Data Import Flow:**
   - Admin imports suppliers from Google Drive â†’ verify data integrity

   **Plan Intelligence Flow (if enabled):**
   - User uploads construction plan â†’ worker processes â†’ quote generated â†’ user views quote

4. Write comprehensive tests:
   ```typescript
   // tests/e2e/full-user-journey.spec.ts
   test('complete user journey: registration to project completion', async ({ page }) => {
     // End-to-end flow testing all integrated features
   });
   ```
5. Configure Playwright:
   ```typescript
   // playwright.config.ts
   export default defineConfig({
     testDir: './tests/e2e',
     fullyParallel: false, // Run sequentially for stability
     retries: 2,
     use: {
       baseURL: 'http://localhost:3000',
       trace: 'on-first-retry',
     },
     projects: [
       { name: 'chromium', use: { ...devices['Desktop Chrome'] } },
     ],
   });
   ```
6. Achieve coverage targets:
   - All critical user flows: 100%
   - All client-required features: 100%
   - All admin features: 100%
7. Run full suite:
   ```bash
   npm run test:e2e
   ```
8. Generate coverage report (if configured)

**Verification:**
```bash
npm run test:e2e
# All tests pass (no flaky tests)

# Review test report
npx playwright show-report
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- All phases (1-7)
- Specific focus:
  - [ ] Tests cover all client features
  - [ ] Tests are reliable (no flakiness)
  - [ ] Test failures block deployment

**PR Gate:**
1. Push branch
2. Create PR: "test: comprehensive e2e test suite for all features"
3. CodeRabbit review
4. Merge to `main`

**Exit Criteria:**
- [ ] Comprehensive e2e test suite written
- [ ] All tests pass locally
- [ ] Test coverage documented
- [ ] PR merged

**Stop Condition:** If tests reveal critical bugs, STOP, fix bugs before merging.

---

### PHASE 11: Staging Environment Setup

**Purpose:** Create staging environment on Vercel for pre-production testing.

**Entry Criteria:**
- [ ] Phase 10 complete
- [ ] All tests passing on `main`

**Actions:**
1. Verify Vercel configuration in CANONICAL:
   ```bash
   cat vercel.json
   # Review configuration
   ```
2. Set up Vercel project:
   ```bash
   # Install Vercel CLI if not present
   npm i -g vercel

   # Login to Vercel
   vercel login

   # Link project
   cd /Users/anitavallabha/goldarch_web_copy/_recovery/CANONICAL
   vercel link
   # Follow prompts to link to existing project or create new
   ```
3. Configure environment variables in Vercel (staging):
   ```bash
   # Set env vars via Vercel dashboard or CLI
   vercel env add NEXT_PUBLIC_SUPABASE_URL
   vercel env add SUPABASE_SERVICE_ROLE_KEY
   vercel env add OPENAI_API_KEY
   vercel env add PINECONE_API_KEY
   vercel env add GOOGLE_CLIENT_ID
   vercel env add GOOGLE_CLIENT_SECRET
   vercel env add NEXT_PUBLIC_ENABLE_FRAMEWORK_B

   # Set environment: Preview (staging)
   ```
4. Create staging branch:
   ```bash
   git checkout -b staging
   git push origin staging
   ```
5. Configure Vercel to deploy `staging` branch to staging environment:
   - Vercel dashboard â†’ Settings â†’ Git â†’ Staging branch: `staging`
6. Deploy to staging:
   ```bash
   vercel --target preview
   # Or push to staging branch triggers auto-deploy
   ```
7. Verify staging deployment:
   - Access staging URL: `https://goldarch-web-staging.vercel.app` (or similar)
   - Test all routes
   - Verify Supabase connection
   - Run smoke tests
8. Run Playwright tests against staging:
   ```bash
   # Update playwright.config.ts
   baseURL: process.env.STAGING_URL || 'http://localhost:3000'

   # Run tests
   STAGING_URL=https://goldarch-web-staging.vercel.app npm run test:e2e
   ```
9. Document staging environment in `DEPLOYMENT.md`

**Verification:**
```bash
# Staging URL accessible
curl -I https://goldarch-web-staging.vercel.app
# Returns 200 OK

# Playwright tests pass against staging
STAGING_URL=https://... npm run test:e2e
```

**Mandatory Self-Review:**
- [ ] Staging environment mirrors production config
- [ ] All env vars set correctly
- [ ] Tests pass against staging
- [ ] No errors in Vercel logs

**PR Gate:** None (infrastructure setup)

**Exit Criteria:**
- [ ] Staging environment deployed
- [ ] All tests pass against staging
- [ ] Staging URL accessible
- [ ] Documentation updated

**Stop Condition:** If staging deployment fails, STOP, debug Vercel configuration.

---

### PHASE 12: Final Pre-Production Validation

**Purpose:** Final checks before production deployment.

**Entry Criteria:**
- [ ] Phase 11 complete
- [ ] Staging environment stable

**Actions:**
1. Pull latest `main`:
   ```bash
   git checkout main
   git pull origin main
   ```
2. Fresh install and build:
   ```bash
   rm -rf node_modules package-lock.json .next
   npm install
   npm run build
   ```
3. Run full test suite:
   ```bash
   npm run lint
   npm test
   npm run test:e2e
   ```
4. Manual smoke test on staging:
   - Test all routes
   - Test all integrations (Supabase, OpenAI, Pinecone, Google Drive)
   - Test all client-required features:
     - Supplier filter UI
     - Template editor
     - RBAC admin UI
     - Google Drive import
   - Test Framework B (if enabled)
   - Test Plan Intelligence
5. Performance check:
   - Lighthouse audit on key pages
   - Check bundle size: `npm run build` â†’ review `.next/` size
   - Check for performance bottlenecks
6. Review documentation:
   - [ ] README.md up-to-date
   - [ ] DEPLOYMENT.md complete
   - [ ] ADMIN_GUIDE.md exists
   - [ ] DATA_IMPORT_GUIDE.md exists
   - [ ] SECURITY.md exists
   - [ ] OPTIONAL_FEATURES.md exists
   - [ ] ROADMAP.md lists deferred features (investor dashboard)
   - [ ] DATABASE_SCHEMA.md documents schema
7. Deployment readiness checklist:
   - [ ] All env vars documented
   - [ ] All Supabase migrations applied
   - [ ] Database seeded (if needed)
   - [ ] No build warnings
   - [ ] All tests pass
   - [ ] Git history clean
   - [ ] All PRs merged
   - [ ] No uncommitted changes
8. Create deployment plan:
   - Deployment time window
   - Rollback plan
   - Monitoring plan (first 24 hours)
9. Client pre-launch review:
   - Demo staging environment to client
   - Walk through all features
   - Obtain sign-off to proceed to production

**Verification:**
```bash
npm run build
npm test
npm run test:e2e
git status
# Clean working tree

# Lighthouse audit
npx lighthouse https://goldarch-web-staging.vercel.app
# Score > 90
```

**Mandatory Self-Review (Code-Integration-Verifier):**
- Phase 8: Progress Gate
  - [ ] All previous reviews completed
  - [ ] No skipped items
  - [ ] Work matches client requirements
  - [ ] Repository clean
  - [ ] Confident in delivery

**PR Gate:** None (validation only)

**Exit Criteria:**
- [ ] All tests pass
- [ ] Documentation complete
- [ ] Staging environment stable
- [ ] Client sign-off obtained
- [ ] Ready for production

**Stop Condition:** If any test fails or client does not sign off, STOP, address issues.

---

### PHASE 13: Production Deployment (Vercel)

**Purpose:** Deploy to production with confidence.

**Entry Criteria:**
- [ ] Phase 12 complete
- [ ] Client sign-off obtained

**Actions:**
1. Verify production environment variables in Vercel:
   - Vercel dashboard â†’ Production environment
   - Set all env vars (same as staging but with production values)
   - Set `NEXT_PUBLIC_ENABLE_FRAMEWORK_B` based on client preference
2. Create production release:
   ```bash
   git checkout main
   git pull origin main
   git tag -a v1.0.0 -m "Production release v1.0.0

   Features:
   - Core CRM (suppliers, projects, documents, tasks, deals, activities)
   - Supplier filter UI with RBAC
   - Template editor (quotations, invoices, emails)
   - RBAC admin UI
   - Google Drive data import
   - Framework B (AI document intelligence) - optional
   - Construction Plan Intelligence

   Client-ready production release.
   "
   git push origin v1.0.0
   ```
3. Deploy to production:
   ```bash
   # Option 1: Vercel auto-deploys from main branch
   git push origin main

   # Option 2: Manual deploy
   vercel --prod
   ```
4. Verify production deployment:
   - Access production URL: `https://goldarch-web.vercel.app` (or custom domain)
   - Smoke test all routes
   - Verify all integrations work
   - Check browser console for errors
   - Test authentication
   - Test one complete user flow
5. Apply Supabase migrations to production database:
   ```bash
   # Connect to production Supabase project
   npx supabase link --project-ref <production-project-ref>

   # Push migrations
   npx supabase db push
   ```
6. Monitor deployment:
   - Vercel dashboard â†’ Deployment logs
   - Check for errors
   - Monitor performance metrics
7. Post-deployment smoke test:
   ```bash
   # Run critical tests against production
   STAGING_URL=https://goldarch-web.vercel.app npm run test:e2e -- tests/e2e/critical-flows.spec.ts
   ```
8. Client notification:
   - Send production URL
   - Provide login credentials
   - Schedule training session

**Verification:**
```bash
# Production URL accessible
curl -I https://goldarch-web.vercel.app
# Returns 200 OK

# Manual smoke test checklist
# [ ] Homepage loads
# [ ] Login works
# [ ] Dashboard routes accessible
# [ ] Supplier filter works
# [ ] Template editor works
# [ ] RBAC works
```

**Mandatory Self-Review:**
- [ ] Deployment successful
- [ ] Production mirrors staging
- [ ] No errors in logs
- [ ] Client can access system

**PR Gate:** None (deploying from `main`)

**Exit Criteria:**
- [ ] Production deployed
- [ ] Production URL accessible
- [ ] All critical features work
- [ ] No errors in logs
- [ ] Client notified

**Stop Condition:** If deployment fails, STOP, rollback to previous version, debug.

**Rollback Plan:**
```bash
# If production broken, rollback via Vercel dashboard
# Vercel â†’ Deployments â†’ Previous deployment â†’ Promote to Production
```

---

### PHASE 14: Client Handoff & Documentation

**Purpose:** Deliver documentation, training, support handoff.

**Entry Criteria:**
- [ ] Phase 13 complete
- [ ] Production stable

**Actions:**
1. Prepare client handoff package:

   **User Documentation:**
   - `USER_GUIDE.md` â€” How to use CRM features
   - `ADMIN_GUIDE.md` â€” How to manage users, roles, templates, imports
   - `DATA_IMPORT_GUIDE.md` â€” Google Drive import instructions
   - `OPTIONAL_FEATURES.md` â€” How to enable Framework B, Plan Intelligence

   **Technical Documentation:**
   - `ARCHITECTURE.md` â€” System architecture overview
   - `DATABASE_SCHEMA.md` â€” Database schema documentation
   - `API_REFERENCE.md` â€” API routes reference
   - `DEPLOYMENT.md` â€” How to deploy, manage environments
   - `SECURITY.md` â€” Security posture, RLS policies

   **Project Documentation:**
   - `ROADMAP.md` â€” Deferred features (investor dashboard), future enhancements
   - `CHANGELOG.md` â€” Version history, release notes
   - `PROJECT_STATE_ANALYSIS_REPORT.md` â€” Historical context
   - `2feb26.md` â€” This delivery plan

2. Create video tutorials (optional):
   - Screen recording of key workflows
   - Admin setup walkthrough
   - Data import demo

3. Conduct client training:
   - Schedule 2-hour training session
   - Walk through:
     - User workflows (create supplier, project, quotation)
     - Admin functions (manage users, roles, templates)
     - Data import (Google Drive)
     - Optional features (Framework B, Plan Intelligence)
   - Q&A session

4. Provide support contact:
   - Define support email/channel
   - Document known issues:
     - Performance limitations (if any)
     - Browser compatibility
     - Known bugs (if any)
   - Provide SLA (to be defined later)

5. Final acceptance:
   - Client acceptance testing period (1 week)
   - Client signs acceptance document
   - Close project

**Verification:**
- [ ] Client can use system independently
- [ ] Client understands all features
- [ ] Documentation delivered
- [ ] Support channel established

**Mandatory Self-Review:**
- [ ] All deliverables provided
- [ ] Client satisfied
- [ ] No outstanding critical issues

**PR Gate:** None (documentation only)

**Exit Criteria:**
- [ ] Client trained
- [ ] Documentation delivered
- [ ] Client acceptance obtained
- [ ] Project closed

---

## 5. Local Test Strategy (Local-First)

### 5.1 Minimum Local Test Matrix

Before **any** push to remote:

| Test Type | Command | Pass Criteria | Stop Condition |
|-----------|---------|---------------|----------------|
| Lint | `npm run lint` | No errors, warnings acceptable (document) | Any error = STOP |
| Build | `npm run build` | Build succeeds, no TypeScript errors | Build fails = STOP |
| Unit/Integration | `npm test` | All tests pass | Any failure = STOP |
| E2E (Playwright) | `npm run test:e2e` | All critical flows pass | Any failure = STOP |

### 5.2 Critical E2E Flows (Playwright)

**Tier 1: Core Flows (Must Pass Before Any Deploy)**

1. **Authentication:**
   - User registration â†’ login â†’ logout
   - Protected route access control

2. **Supplier Management (Client Requirement):**
   - Admin creates supplier â†’ assigns category/region
   - Admin creates access rule â†’ assigns to user
   - Restricted user views filtered supplier list
   - Admin views all suppliers

3. **Project Management:**
   - User creates project â†’ adds tasks â†’ marks complete
   - User views project dashboard

4. **Document Management:**
   - User uploads document â†’ views in library â†’ downloads â†’ deletes

5. **Template System (Client Requirement):**
   - Admin creates quotation template â†’ user generates quote from template

6. **RBAC (Client Requirement):**
   - Admin creates role â†’ assigns permissions â†’ assigns to user
   - User accesses resources based on role

7. **Data Import (Client Requirement):**
   - Admin connects Google Drive â†’ imports Excel â†’ verifies data integrity

**Tier 2: Optional Flows (If Features Enabled)**

8. **Framework B (AI):**
   - User uploads document â†’ asks question in AI chat â†’ receives answer

9. **Plan Intelligence:**
   - User uploads construction plan â†’ worker processes â†’ quote generated

### 5.3 Stop Conditions

| Condition | Action |
|-----------|--------|
| Lint errors | Fix before committing |
| Build fails | Fix before committing |
| Any Tier 1 test fails | STOP, debug, fix, re-run until pass |
| Tier 2 test fails | STOP if feature enabled; document if optional |
| Flaky test (intermittent) | Investigate, stabilize, or remove test |
| Test coverage drops | Add tests to restore coverage |
| New feature without test | Write test before merging |

**Hard Rule:** No push to remote if any Tier 1 test fails. No exceptions.

---

## 6. Risk Register + Mitigations

| Risk ID | Risk Description | Impact | Likelihood | Mitigation |
|---------|------------------|--------|------------|------------|
| R1 | Dual repositories (parent vs. CANONICAL) cause confusion | HIGH | HIGH | **Phase 0:** Archive parent, mark deprecated, operate only in CANONICAL |
| R2 | Quote system divergence (Vision 2 vs. 3) causes conflicts | HIGH | MEDIUM | Use Vision 3 (`quotes` table), archive Vision 2 master plan as reference |
| R3 | Invalid OpenAI API key blocks Plan Intelligence | HIGH | HIGH | **Phase 3:** Replace with valid key, test before deploying |
| R4 | Untracked files lost or cause conflicts | HIGH | MEDIUM | **Phase 2:** Commit all untracked work or explicitly delete |
| R5 | Missing client features (templates, RBAC, import) cause rejection | CRITICAL | HIGH | **Phases 6-8:** Implement all required features, verify with client |
| R6 | Security vulnerabilities (secrets in git, missing RLS, XSS) | CRITICAL | MEDIUM | **Phase 9:** Security audit, secret scanning, RLS verification, CodeRabbit review |
| R7 | Playwright tests fail in CI/staging | MEDIUM | MEDIUM | **Phase 10-11:** Configure Playwright for staging, consistent base URL |
| R8 | Deployment to wrong environment | HIGH | LOW | **Phase 13:** Explicit verification, manual confirmation |
| R9 | Database migrations fail or corrupt data | HIGH | MEDIUM | **Phase 12:** Test migrations on staging first, backup production DB |
| R10 | Code-Integration-Verifier reviews skipped | HIGH | MEDIUM | Make reviews mandatory PR requirement, CodeRabbit enforces |
| R11 | Session timeout during long implementation phase | MEDIUM | HIGH | **Checkpoints:** Each phase ends with clean git state, session handoff doc |
| R12 | Vercel env vars misconfigured | HIGH | MEDIUM | **Phase 11-13:** Document all env vars, verify in staging before production |
| R13 | Google Drive OAuth fails in production | MEDIUM | MEDIUM | **Phase 8:** Test OAuth flow in staging with production credentials |
| R14 | Framework B + Plan Intelligence integration conflicts | MEDIUM | LOW | **Phase 5:** Test integrated system, ensure no resource conflicts (OpenAI rate limits) |
| R15 | Client rejects delivery due to missing investor dashboard | HIGH | LOW | **Phase 12:** Obtain explicit client sign-off on deferred features |

---

## 7. Session Handoff Protocol

### 7.1 End-of-Session Checklist

If Claude Code session approaches limits:

**Before Ending Session:**
1. Commit current work to feature branch:
   ```bash
   git add .
   git commit -m "WIP: [description of current progress]"
   git push origin <branch-name>
   ```
2. Update `SESSION_HANDOFF.md`:
   ```markdown
   # Session Handoff â€” [Date] [Time]

   ## Current Phase
   Phase [X]: [Phase Name]

   ## Status
   - [ ] Phase entry criteria met
   - [x] Actions completed: [list]
   - [ ] Actions remaining: [list]
   - [ ] Verification pending: [list]

   ## Current Branch
   `<branch-name>`

   ## Next Steps
   1. [Next action to take]
   2. [Following action]

   ## Blockers
   - [Any issues encountered]

   ## Notes
   - [Important context for next session]
   ```
3. Push handoff doc:
   ```bash
   git add SESSION_HANDOFF.md
   git commit -m "docs: session handoff [date]"
   git push origin <branch-name>
   ```

**Starting New Session:**
1. Read `SESSION_HANDOFF.md`
2. Checkout working branch:
   ```bash
   git checkout <branch-name>
   git pull origin <branch-name>
   ```
3. Continue from documented next steps

### 7.2 Clean Checkpoint Phases

Phases designed as clean checkpoints for session handoff:
- End of Phase 2: Untracked work committed
- End of Phase 4: Supplier filter complete
- End of Phase 5: Framework B feature-flagged
- End of Phase 6: Template editor complete
- End of Phase 7: RBAC complete
- End of Phase 8: Data import complete
- End of Phase 10: All tests passing
- End of Phase 12: Ready for production

---

## 8. Success Criteria

### 8.1 Technical Success

- [ ] All three visions integrated and functional (CRM + Framework B + Plan Intelligence)
- [ ] All client-required features implemented (supplier filter, templates, RBAC, data import)
- [ ] Investor dashboard documented as deferred (Phase 2)
- [ ] Framework B feature-flagged (optional)
- [ ] All Playwright tests pass (Tier 1: 100%, Tier 2: 100% if enabled)
- [ ] No critical security vulnerabilities
- [ ] Production deployed to Vercel
- [ ] Staging environment stable
- [ ] All documentation complete

### 8.2 Client Success

- [ ] Client understands integrated system (all three visions)
- [ ] Client can use all implemented features
- [ ] Client trained on admin functions
- [ ] Client can import data via Google Drive
- [ ] Client signs acceptance
- [ ] Client has support contact
- [ ] Client has roadmap for deferred features

### 8.3 Project Success

- [ ] Parent repository archived
- [ ] CANONICAL is sole working directory
- [ ] Git history clean
- [ ] All PRs merged via CodeRabbit review
- [ ] All code-integration-verifier reviews completed
- [ ] No scope creep beyond approved features
- [ ] Delivery matches this plan

---

## 9. Post-Delivery Roadmap

### 9.1 Deferred Features (Phase 2)

| Feature | Effort Estimate | Priority | Dependencies |
|---------|----------------|----------|--------------|
| Investor dashboard (read-only project progress) | 2-3 weeks | MEDIUM | None |
| Advanced reporting (custom dashboards) | 3-4 weeks | LOW | None |
| Mobile app (React Native) | 8-12 weeks | LOW | API finalization |
| Webhook integrations (Zapier, etc.) | 1-2 weeks | LOW | None |

### 9.2 Potential Enhancements

- Email notifications (project updates, task assignments)
- Calendar integration (Google Calendar, Outlook)
- Real-time collaboration (multiple users editing project)
- Advanced AI features (predictive pricing, risk assessment)
- Multi-language support
- White-label customization

### 9.3 Maintenance Plan

- Monthly dependency updates
- Quarterly security audits
- Performance monitoring (Vercel analytics)
- Bug fix SLA (to be defined)
- Feature request process (to be defined)

---

## 10. Clarifying Questions â€” ANSWERED

All critical questions answered as of 2026-02-02.

### 10.1 Answered Questions

| Question | Answer | Impact |
|----------|--------|--------|
| 7.1.1 Product Vision | All three visions (CRM + Framework B + Plan Intelligence) | Keep all systems integrated |
| 7.1.2 V1 Features | Template editor, RBAC UI, data import REQUIRED; investor dashboard DEFERRED | Must implement 3 features |
| 7.1.3 Parent Repo | Archive parent; clone needed resources to CANONICAL | Add archival phases |
| 7.1.4 Deployment | Vercel (env vars in parent, config in CANONICAL) | Vercel deployment |
| 7.1.5 Org Invite Flow | Uncertain if client-requested | Verify during audit |
| 7.2.6 Timeline | No fixed deadline, respect session limits | Design clean checkpoints |
| 7.2.7 Data Migration | Yes, Excel via Google Drive | Implement Google Drive import |
| 7.2.8 Staging | Create before production | Add staging phase |
| 7.3.9 Framework B | Keep isolated but documented | Feature flag approach |
| 7.3.10 Support SLA | TBD later | Document as future decision |

---

## END OF PLAN

**Status:** READY FOR EXECUTION

**Next Step:** Begin Phase 0A (Parent Repository Archival)

**Plan Author:** Claude Code (Sonnet 4.5)
**Plan Date:** February 2, 2026
**Plan Version:** 1.0

This plan is approved for execution. Implementation will follow the phased approach with mandatory self-reviews and PR gates.
